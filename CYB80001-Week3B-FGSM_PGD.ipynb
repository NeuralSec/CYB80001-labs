{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CYB80001 System Security Project\n",
    "Prepared by **Derui (Derek) Wang**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3B - Fast Gradient Sign and Projected Gradient Descent\n",
    "\n",
    "In this session, we will implement **Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks** based on **Tensorflow** and **Keras**. We will then apply the attacks to a keras classifier to evaluate the attacks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "\n",
    "### Part 1 Using Tensorflow and Keras together\n",
    "\n",
    "1.1 [Load a pre-trained Keras model into a computational graph](#1_1)\n",
    "\n",
    "1.2 [Using a pre-trained Keras model with Tensorflow variables](#1_2)\n",
    "\n",
    "\n",
    "### Part 2 Using Tensorflow to implement FGSM\n",
    "\n",
    "2.1 [Implementing FGSM](#2_1)\n",
    "\n",
    "2.2 [Testing FGSM](#2_2)\n",
    "\n",
    "2.3 [FGSM Exercise](#2_3)\n",
    "\n",
    "### Part 3 Using Tensorflow to implement PGD\n",
    "\n",
    "3.1 [Implementing PGD](#3_1)\n",
    "\n",
    "3.2 [Testing PGD](#3_2)\n",
    "\n",
    "3.3 [PGD Exercise](#3_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1. Using Tensorflow and Keras together \n",
    "\n",
    "Writing attacks means that you need to build your attack algorithms (in Tensorflow) and attack a victim model via its APIs. In this part, we will learn how to integrate your attacks in Tensorflow and a victim classifiers in Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"1_1\"></a>\n",
    "\n",
    "## 1.1 Load a pre-trained Keras model into a computational graph\n",
    "\n",
    "In this section, we will explore how to craft adversarial examples against a DNN classifier. We will use tensorflow to implement the adversarial example attacks.\n",
    "\n",
    "We will use craft adversarial examples of **MNIST** data. We can import the dataset from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded, training x:(60000, 28, 28, 1), y:(10000, 28, 28, 1); test x:(60000, 10), y(10000, 10).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# we normalise the pixels to values between 0 and 1\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = np.float32(X_train/255.)\n",
    "X_test = np.float32(X_test/255.)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print('data loaded, training x:{0}, y:{1}; test x:{2}, y{3}.'.format(X_train.shape,\n",
    "                                                                     X_test.shape,\n",
    "                                                                     y_train.shape,\n",
    "                                                                     y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target classifier is a trained one. Therefore, we need to retain the model weights during out attack. How can we do this? Recall that Tensorflow has a graph construction phase and a execution phase. We first need to load the target classifier. \n",
    "\n",
    "For example, we can load `mnist_cnn_model.h5` we trained in the Session 3A using `load_model` function from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1014 15:35:48.266674 140736682697664 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1014 15:35:48.306151 140736682697664 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1014 15:35:48.381007 140736682697664 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1014 15:35:48.495921 140736682697664 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1014 15:35:48.496728 140736682697664 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1014 15:35:48.497507 140736682697664 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1014 15:35:48.616253 140736682697664 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1014 15:35:48.831149 140736682697664 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the loaded model\n",
      "10000/10000 [==============================] - 3s 349us/step\n",
      "Accuracy of the loaded model: 0.9916\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "print('Evaluate the loaded model')\n",
    "print(f'Accuracy of the loaded model: {target_classifier.evaluate(X_test, y_test)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a tensorflow graph and use `mnist_cnn_model.h5` as part of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [7 2 1 ... 4 5 6]\n",
      "True labels: [7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "\n",
    "# buid the keras model into a tensorflow graph\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "output =  target_classifier(x)\n",
    "\n",
    "# execute the graph\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we can run the loaded  `mnist_cnn_model.h5` as a tensorflow graph. You must set the keras session and the tensorflow session to be a same one by using `K.set_session(sess)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"1_2\"></a>\n",
    "\n",
    "## 1.2 Using a pre-trained Keras model with Tensorflow variables\n",
    "\n",
    "Remember that if you have used Tensorflow **variables** in the graph, you must run initialisation after the graph is constructed. \n",
    "\n",
    "In the previous section, there is no Tensorflow variable in the graph. Therefore, we did the initialisation **prior to constructing the graph**. In this part, we will experiment with the cases in which we have Tensorflow variables in the graph.\n",
    "\n",
    "First, we add a variable `z` into the graph. **The following code snippet will intentionally raise an error**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "    \n",
    "# buid the keras model into a tensorflow graph\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "# We use a variable here\n",
    "z = tf.Variable(np.zeros((X_test.shape[0],\n",
    "                          X_test.shape[1],\n",
    "                          X_test.shape[2],\n",
    "                          X_test.shape[3])), dtype=tf.float32, name='tf_variable_z')\n",
    "\n",
    "new_x = tf.clip_by_value(x + z, 0, 1)\n",
    "output =  target_classifier(new_x)\n",
    "\n",
    "# execute the graph\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You recieve an error here. To resolve it, **you must run an initialisation operation after declaring all the variables, right before the learning loop**. Let's add the initialisation operation and run the code again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "    \n",
    "# buid the keras model into a tensorflow graph\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "# We use a variable here\n",
    "z = tf.Variable(np.zeros((X_test.shape[0],\n",
    "                          X_test.shape[1],\n",
    "                          X_test.shape[2],\n",
    "                          X_test.shape[3])), dtype=tf.float32, name='tf_variable_z')\n",
    "\n",
    "new_x = tf.clip_by_value(x + z, 0, 1)\n",
    "output =  target_classifier(new_x)\n",
    "\n",
    "# define an initialisation operation to initialise all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is no error now. However, **the prediction results become incorrect**. This is because the Keras model was initialised as well.\n",
    "\n",
    "Then, **how can we use Tensorflow variables and keras model together?** Let's simply change the order of the initialisation operation and model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "# We use a variable here\n",
    "z = tf.Variable(np.zeros((X_test.shape[0],\n",
    "                          X_test.shape[1],\n",
    "                          X_test.shape[2],\n",
    "                          X_test.shape[3])), dtype=tf.float32, name='tf_variable_z')\n",
    "\n",
    "# Put the init op before loading model\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# load model after the init op\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "new_x = tf.clip_by_value(x + z, 0, 1)\n",
    "\n",
    "# buid the keras model into a tensorflow graph\n",
    "output =  target_classifier(new_x)\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the correct predictions. **As a conclusion, we can first define an initialisation operation after all Tensorflow variables and then load a Keras model into the graph**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2. Using Tensorflow to implement FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"2_1\"></a>\n",
    "\n",
    "## 2.1 Implementing FGSM\n",
    "We will implement the FGSM attack from scratch in this part.\n",
    "\n",
    "We use `categorical_crossentropy` from Keras, as the adversarial loss function.\n",
    "\n",
    "We first implement **non-targeted** FGSM (the misclassification calss is not specified). In this case, we are going to increase the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Normal_inputs (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "C2 (Conv2D)                  (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "MP1 (MaxPooling2D)           (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "D1 (Dense)                   (None, 200)               1254600   \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "normal_output (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,266,178\n",
      "Trainable params: 1,266,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# FGSM hyper-parameter\n",
    "eps = 0.15\n",
    "benign_example = X_test[4:5]\n",
    "bening_y = y_test[4:5]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (benign_example.shape[0],\n",
    "                                benign_example.shape[1],\n",
    "                                benign_example.shape[2],\n",
    "                                benign_example.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (bening_y.shape[0], bening_y.shape[1]))\n",
    "\n",
    "# Put the init op before loading model\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# load model after the init op\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "target_classifier.summary()\n",
    "\n",
    "# buid the keras model into a tensorflow graph\n",
    "output =  target_classifier(x)\n",
    "\n",
    "# adversarial loss function\n",
    "loss = K.categorical_crossentropy(output, y)\n",
    "\n",
    "# FGSM attack steps\n",
    "dy_dx, = tf.gradients(loss, x)\n",
    "x_adv = tf.stop_gradient(x + eps * tf.sign(dy_dx))\n",
    "x_adv = tf.clip_by_value(x_adv, 0, 1)\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "fgsm_x = sess.run(x_adv, feed_dict={x: benign_example, y: bening_y})\n",
    "print('Complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fgsm_x` is the adversarial example. We can plot the MNIST example and its FGSM example using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(benign_example.reshape(28,28), cmap='gray')\n",
    "axes[1].imshow(fgsm_x.reshape(28,28), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"2_2\"></a>\n",
    "\n",
    "## 2.2 Testing FGSM\n",
    "\n",
    "We can check the classification results of these two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier prediction on the benign example: 4\n",
      "Keras classifier prediction on the fgsm example: 9\n"
     ]
    }
   ],
   "source": [
    "# Input the examples into the classifier for classification\n",
    "print(f'Keras classifier prediction on the benign example: {np.argmax(target_classifier.predict(benign_example))}')\n",
    "print(f'Keras classifier prediction on the fgsm example: {np.argmax(target_classifier.predict(fgsm_x))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that **the fgsm example is misclassified**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"2_3\"></a>\n",
    "\n",
    "## 2.3 FGSM Exercise\n",
    "\n",
    "We have implemented the **non-targeted FGSM** attack in the above code snippets. \n",
    "\n",
    "As an exercise, you can implement the **targeted FGSM** attack which produces an adversarial example of **digit 4**. You can set the misclassification target to **0**. You can reuse the above code and data in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please complete the exercise in this ocde cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3. Using Tensorflow to implement PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"3_1\"></a>\n",
    "\n",
    "## 3.1 Implementing PGD\n",
    "\n",
    "We will implement the PGD attack from scratch in this part.\n",
    "\n",
    "We use `categorical_crossentropy` from Keras, as the adversarial loss function.\n",
    "\n",
    "We first implement **non-targeted** PGD (the misclassification calss is not specified). We will write the attack steps in a function named `pgd_attack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def pgd_attack(model, x, y, max_iter=1000, clip_min=0., clip_max=1.):\n",
    "    def _cond(x, i):\n",
    "        return tf.less(i, max_iter)\n",
    "\n",
    "    def _body(x, i):\n",
    "        logits = model(x)\n",
    "        loss = K.categorical_crossentropy(logits, y)\n",
    "        dy_dx, = tf.gradients(loss, x)\n",
    "        x = tf.stop_gradient(x + dy_dx)\n",
    "        x = tf.clip_by_value(x, clip_min, clip_max)\n",
    "        return x, i+1\n",
    "    x_adv, i = tf.while_loop(_cond, _body, (x, 0), back_prop=False, name='pgd_attacker')\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then replace the attack steps of the FGSM attack to that of the PGD attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Normal_inputs (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "C2 (Conv2D)                  (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "MP1 (MaxPooling2D)           (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "D1 (Dense)                   (None, 200)               1254600   \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "normal_output (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,266,178\n",
      "Trainable params: 1,266,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# PGD hyper-parameter\n",
    "MAX_ITER = 5000\n",
    "\n",
    "benign_example = X_test[4:5]\n",
    "bening_y = y_test[4:5]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (benign_example.shape[0],\n",
    "                                benign_example.shape[1],\n",
    "                                benign_example.shape[2],\n",
    "                                benign_example.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (bening_y.shape[0], bening_y.shape[1]))\n",
    "\n",
    "# Put the init op before loading model\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# load model after the init op\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "#target_classifier.layers.pop()\n",
    "target_classifier.summary()\n",
    "\n",
    "# Attack steps\n",
    "x_adv = pgd_attack(target_classifier, x, y, max_iter=MAX_ITER)\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "pgd_x  = sess.run(x_adv, feed_dict={x: benign_example, y: bening_y})\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(benign_example[0].reshape(28,28), cmap='gray')\n",
    "axes[1].imshow(pgd_x[0].reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"3_2\"></a>\n",
    "\n",
    "## 3.2 Testing PGD\n",
    "\n",
    "We can check the classification results of these two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the examples into the classifier for classification\n",
    "print(f'Keras classifier prediction on the benign example: {np.argmax(target_classifier.predict(benign_example))}')\n",
    "print(f'Keras classifier prediction on the fgsm example: {np.argmax(target_classifier.predict(pgd_x))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"3_3\"></a>\n",
    "\n",
    "## 3.3 PGD Exercise\n",
    "\n",
    "We have implemented the **non-targeted PGD** attack in the above code snippets. \n",
    "\n",
    "As an exercise, you can implement the **targeted PGD** attack which produces an adversarial example of **digit 4**. You can set the misclassification target to **0**. You can reuse the above code and data in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please complete the exercise in this ocde cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <div  style=\"text-align:center\">**THE END**</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
